% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------

\documentclass[12pt]{article}


\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb,scrextend, physics, breqn, dsfont}
\usepackage{comment}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage{graphicx}
\usepackage{tikz-cd}
\usepackage{fancyhdr}
\pagestyle{fancy}


\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\s}{\mathbb{S}}
\newcommand{\CP}{\mathbb{CP}}
\renewcommand{\Im}{\operatorname{Im}}
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\qed}{\hfill$\blacksquare$}
\newcommand{\diff}{\mathop{}\!d}
\let\newproof\proof
\renewenvironment{proof}{\begin{addmargin}[1em]{0em}\begin{newproof}}{\end{newproof}\end{addmargin}\qed}
% \newcommand{\expl}[1]{\text{\hfill[#1]}$}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\begin{document}

% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------

\lhead{}
\chead{Erik Herrera}
\rhead{\today}
\title{The Exterior Derivative}
\author{Erik Herrera}

\maketitle

The exterior derivative on differential forms is a foundational concept in differential topology. It features prominently in many well-known theorems and constructions such as Stokes's theorem and De Rham cohomology. Despite its importance, many introductory texts do not emphasize a geometric understanding of the exterior derivative, opting instead to give an algebraic \cite{lee} or coordinate-based \cite{spivak} description. One exception to this pattern is Arnold's Mathematical Methods of Classical Mechanics, which defines the exterior derivative through the "infinitesimal flux" of a form \cite{arnold}. However, Arnold omits a proof that this definition is well-defined, and his proof of equivalence with the standard coordinate-based definition is terse and unenlightening. In this note, we hope to  fill these gaps in Arnold's exposition.

It may be helpful to first review how the divergence of a vector field is given by the infinitesimal flux. Let $V = (V_x, V_y, V_z)$ be a vector field on $\R^3$, $p = (p_x, p_y, p_z)$ a point in $\R^3$, and $C_\varepsilon$ the cube $[p_x, p_x+\varepsilon] \times [p_y, p_y+\varepsilon] \times [p_z, p_z + \varepsilon]$. The flux $F(\varepsilon)$ of $V$ through the boundary of $ C_\varepsilon$ is given by
\begin{dmath*}
F(\varepsilon) = \int_{C_\varepsilon^{right}} V \cdot \hat x -\int_{C_\varepsilon^{left}} V \cdot \hat x + \int_{C_\varepsilon^{top}} V \cdot \hat y - \int_{C_\varepsilon^{bottom}} V\cdot \hat y +  \int_{C_\varepsilon^{front}} V \cdot \hat z - \int_{C_\varepsilon^{back}} V \cdot \hat z
\end{dmath*}
which can be rewritten as
\begin{dmath*}
F(\varepsilon) = \int_{p_y}^{p_y+\varepsilon} \int_{p_z}^{p_z+ \varepsilon} V_x(p_x + \varepsilon, y, z) - V_x(p_x, y, z) \diff z \diff y \\
+ \int_{p_x}^{p_x+\varepsilon} \int_{p_z}^{p_z+\varepsilon} V_y (x, p_y + \varepsilon, z) - V_y(x, p_y, z) \diff z \diff x\\
+\int_{p_x}^{p_x+\varepsilon} \int_{p_y}^{p_y+\varepsilon} V_z(x, y, p_z + \varepsilon) - V_z(x, y, p_z) \diff y \diff x
\end{dmath*}
The first term in each integral can be approximated with a Taylor series in $\varepsilon$. The expression therefore becomes
\begin{dmath*}
F(\varepsilon) = \int_{p_y}^{p_y+\varepsilon} \int_{p_z}^{p_z+ \varepsilon} \varepsilon \frac{\partial V_x} {\partial x} (p_x, y, z) + o(\varepsilon)\diff y \diff z
+ \int_{p_x}^{p_x+\varepsilon} \int_{p_z}^{p_z+\varepsilon} \varepsilon \frac{\partial V_y}{\partial y}(x, p_y, z) +o(\varepsilon)\diff x \diff z\\
+\int_{p_x}^{p_x+\varepsilon} \int_{p_y}^{p_y+\varepsilon} \varepsilon \frac{\partial V_z}{\partial z} (x, y, p_z) + o(\varepsilon) \diff x \diff y
\end{dmath*}
The integrands can also be approximated with a Taylor series in the variables of integration. This yields
\begin{dmath*}
F(\varepsilon) = \varepsilon^3 \left (\frac{\partial V_x}{\partial x} (p) + \frac{\partial V_y}{\partial y} (p) + \frac{\partial V_z}{\partial z} (p) \right) + o(\varepsilon^3)
\end{dmath*}
Therefore, the divergence of $V$ is given by the leading order term in $\varepsilon$ of the flux through $\partial C_\varepsilon$. In particular,
$$
\nabla \cdot V (p) = \lim_{\varepsilon \to 0}\frac{ \int_{\partial C_\varepsilon} V \cdot \hat n}{\varepsilon^3} = \lim_{\varepsilon \to 0} \frac{F(\varepsilon)}{\varepsilon^3}
$$
The same result holds for vector fields on $\R^n$, but the leading order term is proportional to $\varepsilon ^n$ in that case.

We claim that the exterior derivative is similarly given by the infinitesimal flux of a differential form. Let $M$ be an $n$-dimensional manifold and $\omega$ a differential $k$-form on $M$. Suppose $\varphi: [0, 1]^{k+1} \to M$ is an embedding of a $(k+1)$-cube in $M$ so that $\varphi(0) = p \in M$ and let $v_i = d\varphi \left (\frac{\partial}{\partial x_i} \right)$ be the coordinate vector fields induced by $\varphi$. We denote the restriction of $\varphi$ to a cube of side-length $\varepsilon$ by $\varphi_\varepsilon: [0, \varepsilon]^{k+1} \to M$. We will define
\begin{dmath}
d\omega_p (v_1, \ldots, v_{k+1}) =  \lim_{\varepsilon \to 0} \frac{\int _{\partial (\Im \varphi_\varepsilon )} \omega}{\varepsilon^{k+1}} \label{def}
\end{dmath}
in analogy with the divergence.

Before we proceed, we should compare this with the previous example. In the present case, we have some freedom in choosing the cube of integration by choosing the $v_i$s and $\varphi$ whereas in the divergence case we only considered cubes given by the coordinate directions\footnote{See the appendix for a proof that a suitable $\varphi$ exists for any set of $v_i$s}. In the present case, the dimension of the cube of integration depends on the degree of the form $\omega$ whereas in the previous case the cube of integration had to be $n$. Here, $\omega$ is playing the role of $V \cdot \hat n$ by computing the flux through each portion of the boundary.

As an aside, $V \cdot \hat n$ can be regarded as an $(n-1)$-form. Given $n-1$ vectors, the corresponding differential form gives the projection of $V$ onto the direction perpendicular to a given plane spanned by those vectors. This can be made precise using the Hodge dual.


In order for \eqref{def} to be well-defined, we must check that this infinitesimal flux depends only the the values of $v_i$ at $p$ and not on the choice of $\varphi$. We should also show that this definition indeed makes $d \omega$ a $(k+1)$-form. Lastly, we should check that this definition of $d\omega$ agrees with the usual definition in coordinates.

We begin by finding an expression for the flux over $\partial (\Im \varphi_\varepsilon)$. To make our calculation simpler, we will work in the coordinates given by $\varphi$. Pulling back along $\varphi$, we get the following:
\begin{dmath}
\int_{\partial \left ([0, \varepsilon]^{k+1} \right)} \varphi^*(\omega)
\label{flux}
\end{dmath}
We will first compute the flux through the planes perpendicular the $x_1$-direction. This is given by
$$
\int_{[0, \varepsilon]^k} \varphi^*(\omega)_{(\varepsilon, y)} \left (\frac{\partial}{\partial x_2}, \ldots, \frac{\partial }{\partial x_{k+1}} \right)
- \varphi^* (\omega)_{ (0, y)}\left (\frac{\partial}{\partial x_2}, \ldots, \frac{\partial }{\partial x_{k+1}} \right)  \diff y
$$
The integrand is approximated by the derivative of the function $\omega \left ( \frac{\partial }{\partial x_2}, \ldots, \frac{\partial }{\partial x_{k+1}} \right)$ in the $x_1$-direction. Thus, we have
$$
\int_{[0, \varepsilon]^k} \varepsilon \frac{\partial}{\partial x_1}\left ( \varphi^*(\omega) \left (\frac{\partial}{\partial x_2}, \ldots, \frac{\partial }{\partial x_{k+1}} \right) \right) \bigg |_{(0, y)} + o (\varepsilon)\diff y
$$
By approximating this integrand with a Taylor series in $y$, the integral becomes
$$
\varepsilon^{k+1} \frac{\partial}{\partial x_1}\left ( \varphi^*(\omega) \left (\frac{\partial}{\partial x_2}, \ldots, \frac{\partial }{\partial x_{k+1}} \right) \right) \bigg |_{0} + o (\varepsilon^{k+1})
$$
The flux in the other directions can be computed similarly. The desired limit in $\eqref{def}$ is therefore
$$
\sum_{i = 1}^{k+1} (-1)^{i+1}\frac{\partial}{\partial x_i}\left ( \varphi^*(\omega) \left (\frac{\partial}{\partial x_1}, \ldots, \widehat {\frac{\partial}{\partial x_i}}, \ldots, \frac{\partial }{\partial x_{k+1}} \right) \right)
$$
where the hat indicates omission of that term. The factor of $(-1)^{i+1}$ is due to the orientation induced on the boundary of $\Im \varphi_\varepsilon$. We can rewrite this using more coordinate-free language as
\begin{dmath}
d \omega (v_1, \ldots, v_{k+1}) =
\sum_{i = 1}^{k+1}(-1)^{i+1} v_i \left ( \omega  \left (v_1, \ldots, \hat v_i, \ldots, v_{k+1}\right) \right)
\label{sum}
\end{dmath}
We can check that \eqref{sum} agrees with the formula for the exterior derivative in coordinates. Suppose $y_1, \ldots, y_n$ define coordinates on $M$ around $p$. Let $u_1, \ldots, u_n$ denote the corresponding coordinate vector fields and let $\omega = g(y) dy_{i_1} \wedge \ldots \wedge dy_{i_k}$. We then see that
$$
d\omega(u_{i_1}, \ldots, u_{i_{k+1}}) = (-1)^{k}\frac{\partial g}{\partial y_{i_{k+1}}}
$$
since all but the last term of \eqref{sum} vanish. Therefore,
$$
d \omega = \sum_{j=1}^n \frac{\partial g}{\partial y_j} dy_j \wedge dy_{i_1} \wedge\ldots \wedge dy_{i_k}
$$
which is the standard description of the exterior derivative in coordinates.


One can verify directly that \eqref{sum} is multilinear over $C^\infty (M)$ and therefore a tensor. However, doing so requires the fact that the $v_i$s are coordinate vector fields and commute. Moreover, this formula \textit{only} holds for commuting vector fields. While it is always possible to extend $k+1$ vectors at $p$ to commuting vector fields as we have done, it would be ideal to have a version of this formula that is more manifestly multilinear and works for arbitrary vector fields.

Recall that $v_i (\omega(v_1, \ldots, \hat v_i, \ldots, v_{k+1})) = \mathcal L_{v_i} (\omega (v_1, \ldots, \hat v_i, \ldots, v_{k+1}))$ where $\mathcal L$ is the Lie derivative and that the Lie derivative satisfies
\begin{dmath}
\mathcal L_v (\omega (u_1, \ldots, u_k)) = (\mathcal L_v \omega) (u_1, \ldots, u_k) + \sum_{j=1}^k (-1)^{j+1} \omega([v, u_j], u_1, \ldots, \hat u_j, \ldots, u_k)
\label{lie}
\end{dmath}
where $v, u_1, \ldots, u_k$ are vector fields. Applying this to \eqref{sum}, we get
\begin{dmath}
\sum_{i=1}^{k+1} (-1)^{i+1} (\mathcal L_{v_i} \omega) (v_1, \ldots, \hat v_i, \ldots, v_{k+1})
+ \sum_{i> j} (-1)^{i+j} \omega ([v_i, v_j], v_1, \ldots, \hat v_j, \ldots, \hat v_i, \ldots, v_{k+1})
+ \sum_{i < j} (-1)^{i+j+1} \omega ([v_i, v_j], v_1,\ldots, \hat v_i, \ldots, \hat v_j, \ldots, v_{k+1})
\end{dmath}
Because the $v_i$s commute, we may safely drop the last sum. Using \eqref{lie} again, we see that
\begin{dmath}
d\omega(v_1, \ldots, v_{k+1}) =
\sum_{i = 1}^{k+1}(-1)^{i+1} v_i \left ( \omega  \left (v_1, \ldots, \hat v_i, \ldots, v_{k+1}\right) \right)
+ \sum_{i < j} (-1)^{i+j} \omega ([v_i, v_j],v_1, \ldots, \hat v_i, \ldots, \hat v_j, \ldots, v_{k+1})
\label{inv}
\end{dmath}
It turns out that \eqref{inv} is multilinear even for vector fields that do not commute, so this is a coordinate-free equation that computes the exterior derivative for arbitrary vector fields. We could have directly gone from \eqref{sum} to \eqref{inv} since each $[v_i, v_j]$ vanishes for coordinate vector fields, but this detour gives some insight as to why the second sum appears.

It is straightforward to see that \eqref{inv} changes sign if we interchange $v_\ell$ and $v_{\ell+1}$. This is because $[v_\ell, v_{\ell+1}] = - [v_{\ell+1}, v_\ell]$ and $\omega$ is alternating. Therefore, \eqref{inv} is alternating.
Verifying that this formula is multilinear over $C^\infty (M)$ is also straightforward. Replacing $v_1$ with $fv_1$ gives
\begin{dmath}
\sum_{i = 1}^{k+1}(-1)^{i+1}f v_i \left ( \omega  \left (v_1, \ldots, \hat v_i, \ldots, v_{k+1}\right) \right)
+\sum_{i=2}^{k+1} (-1)^{i+1} v_i(f) \omega (v_1, \ldots, \hat v_i, \ldots, v_{k+1})
+ \sum_{i < j} (-1)^{i+j}f \omega ([v_i, v_j],v_1, \ldots, \hat v_i, \ldots, \hat v_j, \ldots, v_{k+1})
+\sum_{j=2}^{k+1} (-1)^{j} v_j(f) \omega (v_1, \ldots, \hat v_j, \ldots, v_{k+1})
\end{dmath}
since $[fv_1, v_j] = f[v_1, v_j] -v_j(f)v_1$. The second and fourth sums cancel, showing that \eqref{inv} is linear in the first variable. Because it is alternating, \eqref{inv} is linear over $C^\infty(M)$ in the other variables as well. Thus, it defines a tensor and a $(k+1)$-form as anticipated. Therefore, it depends only on the pointwise values of the vector fields. In particular, it is independent of the choice of $\varphi$ and it is independent of the values of the $v_i$s away from $p$.

The utility of an intrinsic definition of the exterior derivative should be self-evident, but there are concrete insights this understanding provides. One benefit of definition \eqref{def} is that it elucidates why something like Stokes' theorem may be true. This definition essentially defines $d \omega$ to be the quantity so that the approximation
$$
\int_{\partial C_\varepsilon} \omega \approx \varepsilon^{k+1} d \omega \approx \int _{C_\varepsilon} d \omega
$$
holds for small $\varepsilon$. Stokes' theorem is a macroscopic analogue of this statement.


\section*{Appendix}

The reader may worry that it is not possible to always find some $\varphi$ for an arbitrary tuple of vectors $v_1, \ldots, v_{k+1}$ at $p$. However, it is indeed always possible. Choose any system of local coordinates for $M$ around $p$. By translation and radial scaling, we can produce coordinates $x_1, \ldots, x_n$ such that $x(p) = 0$ and the image of $(x_1, \ldots, x_n)$ is all of $\R^n$. Using a linear change of coordinates, we can ensure that $dx (v_i) = \frac{\partial }{\partial x_i}$. We can then take $\varphi$ to be $x^{-1}$ restricted to $[0, 1]^{k+1} \times \{0\}$.


\begin{thebibliography}{9}
\bibitem{arnold}
V. I. Arnold (1989) \emph{Mathematical Methods of Classical Mechanics}, Springer, 2nd ed.

\bibitem{lee}
John M. Lee (2012) \emph{Introduction to Smooth Manifolds}, Springer, 2nd ed.

\bibitem{spivak}
Michael Spivak (1965) \emph{Calculus on Manifolds}, Addison-Wesley.
\end{thebibliography}












% --------------------------------------------------------------
%     You don't have to mess with anything below this line.
% --------------------------------------------------------------

\end{document}

